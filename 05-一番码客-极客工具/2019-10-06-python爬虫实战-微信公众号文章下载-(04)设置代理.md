---
title: python爬虫实战-微信公众号文章下载-(04)设置代理
date: 2019-10-06
tags: 
categories: 极客工具
---

> **一番码客 : 挖掘你关心的亮点。**
> **http://efonfighting.imwork.net**

本文目录：

[TOC]

## 前言

时隔半年，一番再次写公众号文章下载系列的文章。

微信公众号设置了访问次数限制，据一番实践，现在一个ip地址每天只能下载两千篇文章。为了破解这个限制，我们就需要设置下代理。简单讲就是通过另一ip访问微信服务器，然后将获得信息传送回我们本地。

在python里设置代理也非常简单。

<!-- more -->

## 设置代理

这里我们用到的就是`request`库，`request.get`里便可以通过`proxies`字段设置代理。为了伪装成浏览器，还可以用`headers`字段设置访问头。

具体代码如下（为了防止敏感信息泄露，代码里用`x`和`.`代替了一些信息，小伙伴们可以自行获得代理和自己的访问头之后设置）。真的非常简单。

```python
def open_url(url_str):
    http_ip = [
        '119.101.xxx.xxx:9999',
        '125.40.xxx.xxx:56738',
        '139.198.xxx.107:1080',
        '106.15.xxx.xxx:33543',
        '183.185.xxx.xxx:80'
    ]

    proxy_ip = {
    'http' : random.choice(http_ip),
    }
    print('使用代理的IP:',proxy_ip)
    html = ""
    headers = {
        "User-Agent":"Mozilla/5.0 (Windows NT 10.0; WOW64; rv:43.0) ....",
        "Accept-Language":"zh-CN,zh;q=0...",
        "Accept-Encoding":"gzip, de...",
        "Connection":"..."
    }
    if bool(proxy_ip):
        html = requests.get(url=url_str.replace('http:', 'https:'), timeout=20, headers = headers, proxies=proxy_ip).content
        
    else:
        html = requests.get(url=url_str, timeout=20, headers = headers).content
    #返回网页内容,动态加载的需要另行处理
    print('返回网页内容长度:',len(html))
    return html
```

## 一番今日

从4号回成都到今天6号了，都想不起干了些什么了，流逝太快了，还有一天就要上班了。

最近写的关于`electron`的技术文章有点水，最近写日更也有点弹尽粮绝了，写文章有点吃了这顿不知道下顿在哪里的感觉。

想着这是一个信息过载的时代，网上那么多资源可供学习，自己也付费买了些课程，但看完的几乎没有。面对这样的处境，一个是需要加强时间管理，自己开发一些信息管理的小工具，一个还是在书中去找答案吧。

为了充分挤出时间，随时带书在身上的同时，还是要随时拿出来阅读，减少手机的零散使用，想想最近的这六天假期，手机看的这些信息，真的想不出有什么沉淀，还不如沉浸在书里，做个单纯专注的阅读者。

> 一番雾语：学而不思则罔，思而不学则殆。



> **免费知识星球： [一番码客-积累交流]([wwww](https://t.zsxq.com/NRVBURr))**
> **微信公众号：一番码客**
> **微信：Efon-fighting**
> **网站： http://efonfighting.imwork.net**