---
title: python获取微信公众号文章里的网页图片
date: 2019-09-25
tags: 
categories: 极客工具
---

> **一番码客 : 挖掘你关心的亮点。**
> **http://efonfighting.imwork.net**

本文目录：

[TOC]

## 日更前语

昨天一番为electron写了个开篇，本来今天应该继续的，但一番回来收拾完了快10点了，吃了夜宵看了电影都12点了。好吧，工作太累，放松一下。现在开始些文章了。没时间研究electron了，所以继续写写python吧，这样的方式写python，写一年也写不完啊（捂脸）。



## 命令行方式

会linux的小伙伴们应该知道，linux里有一个命令——“wget”。用这个命令可以从一个网址下载想要的东西。比如一番知道了一篇公众号文章的链接地址。那么可以通过`wget`命令将这个网页下载下来保存到本地。

```shell
wget https://mp.weixin.qq.com/s/hGlIYPV_P16RAset3Kk_lQ -O essay.html
```

![1569430802751](2019-09-25-python获取微信公众号文章里的网页图片\pic01.png)

下载下来后，我们用浏览器打开，发现图片无法显示。

![1569430864817](2019-09-25-python获取微信公众号文章里的网页图片\pic02.png)

这时我们用文本编辑器打开html文件，会发现一个`data-src`字段，这个字段就是图片地址的字段。

![1569431077908](E:\01_blog\efonmark-blog\05-一番码客-极客工具\2019-09-25-python获取微信公众号文章里的网页图片\pic03.png)

我们将其内容链接复制后用浏览器打开，发现确实是我们网页上的图片。

![1569431265213](E:\01_blog\efonmark-blog\05-一番码客-极客工具\2019-09-25-python获取微信公众号文章里的网页图片\pic04.png)

这时我们用wget工具去下载

```shell
wget https://mmbiz.qpic.cn/mmbiz_png/gAXAm0302ofV183q8rwKKKEHGAyWkFCeewcrwDM12M4BngTEe1HF97vic794j0YOd0HO08esMTDt20ibVxF7Xguw/640?wx_fmt=png -O 1.png
```

![1569431354520](E:\01_blog\efonmark-blog\05-一番码客-极客工具\2019-09-25-python获取微信公众号文章里的网页图片\pic05.png)

以上可以说是用linux自带命令的方式实现的网页上图片的下载了。



## python代码方式

不罗嗦，先上代码。

```python
def saveUrl(url, picName):
    '''
    保存url内容
    :param url : 要保存的url
    :param picName : 保存文件路径
    :return : 获取到的url内容长度
    '''
    contLen = 0
    try:
        urlCont = requests.get(url, timeout=20).content
        contLen = len(urlCont)

        if (contLen == 0): # 第一次失败则再尝试一次
            print("get url failed,try again.")
            urlCont = requests.get(url, timeout=20).content
            contLen = len(urlCont)

        if (contLen != 0):
            open(picName, 'wb').write(urlCont)
            print("get url ok:", contLen)
        else:
            print("get url failed.")
    except Exception:
        print("get url Exception.")
    return contLen
```

前面是说的用`wget`有个问题，如果再大批量的下载中，wget没有返回值，不能做超时处理。

所以我们需要用python代码的方式，这里主要用的是`requests`方法。

如代码所示，先获取到链接对应的内容，然后将获取的内容保存即可。

可以做超时，可以做代理，比`wget`命令强大多了，也更灵活。



> 一番雾语：我们行走在这世上，善恶美丑散落在我们行走的每一寸土地上，我们拾起什么，便带走什么。



> **免费知识星球： [一番码客-积累交流]([wwww](https://t.zsxq.com/NRVBURr))**
> **微信公众号：一番码客**
> **微信：Efon-fighting**
> **网站： http://efonfighting.imwork.net**